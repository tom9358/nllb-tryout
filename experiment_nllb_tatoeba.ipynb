{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading necessary Tatoeba files...\n",
      "Links CSV already exists. Skipping download and unpacking.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 2359.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tatoeba/nld_sentences.tsv already exists. Skipping download and unpacking.\n",
      "tatoeba/gos_sentences.tsv already exists. Skipping download and unpacking.\n",
      "Setting up parallel corpus for nld_Latn gos_Latn\n",
      "Downloading necessary Tatoeba files...\n",
      "Links CSV already exists. Skipping download and unpacking.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 10267.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tatoeba/nld_sentences.tsv already exists. Skipping download and unpacking.\n",
      "tatoeba/gos_sentences.tsv already exists. Skipping download and unpacking.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from config import config\n",
    "from downloadtatoeba import main_download\n",
    "from corpus import main_corpus\n",
    "from train import main_train\n",
    "from evaluate import main_evaluate\n",
    "from tryout import main_tryout\n",
    "\n",
    "# Step 1: Download data\n",
    "main_download(config[\"source_langs_tatoeba\"])\n",
    "\n",
    "# Step 2: Load and create parallel corpus\n",
    "corpus_objects = main_corpus(config[\"source_langs_tatoeba\"], config[\"source_langs_nllb\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.is_available(): True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tom.brand/Offline/nllb-tryout/nllb-tat/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/tom.brand/Offline/nllb-tryout/nllb-tat/lib/python3.10/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/tom.brand/Offline/nllb-tryout/nllb-tat/lib/python3.10/site-packages/transformers/modeling_utils.py:488: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=map_location)\n",
      "/home/tom.brand/Offline/nllb-tryout/nllb-tat/lib/python3.10/site-packages/transformers/modeling_utils.py:488: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=map_location)\n",
      "/home/tom.brand/Offline/nllb-tryout/nllb-tat/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 256205. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized weights for gos_Latn equal to those of nld_Latn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Steps: 100%|██████████| 800/800 [07:44<00:00,  1.72it/s, loss=0.415]\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Train the model\n",
    "main_train(corpus_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from models/facebook/nllb-200-distilled-1.3B-nld-gos-20250331-182640/799...\n",
      "torch.cuda.is_available(): True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tom.brand/Offline/nllb-tryout/nllb-tat/lib/python3.10/site-packages/transformers/modeling_utils.py:488: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=map_location)\n",
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 256205. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n",
      "Enter text to translate. Type 'END' to exit or use 'LANG src tgt' to change languages. Format e.g. nld_Latn gos_Latn\n",
      "Translate (nld_Latn -> gos_Latn): ik ben benieuwd of dit werkt.\n",
      "Translation: ik bin nieuwsgierig of dit waarkt.\n",
      "Translate (nld_Latn -> gos_Latn): jij bent het zusje van mijn buurman!\n",
      "Translation: doe bist t zuske van mien noaber!\n",
      "Translate (nld_Latn -> gos_Latn): onverwachts kwamen de ouders van Bert op bezoek.\n",
      "Translation: onwaarschijnlijk kwammen olders van Bert op veziede.\n",
      "Translate (nld_Latn -> gos_Latn): de straatkat is een kat die op straat leeft.\n",
      "Translation: stroatkat is n kadde dij op stroat leeft.\n",
      "Translate (nld_Latn -> gos_Latn): hebben jullie dat gezegd?\n",
      "Translation: hebben joe dat zègd?\n",
      "Translate (nld_Latn -> gos_Latn): de molenaar ziet jullie.\n",
      "Translation: mulder zain joe.\n",
      "Translate (nld_Latn -> gos_Latn): ik weet niet wat je bedoelt...\n",
      "Translation: k Wait nait watst bedoulst...\n",
      "Translate (nld_Latn -> gos_Latn): wiens linkerarm is het sterkste? die van mij.\n",
      "Translation: wel zien linker aarm is t staarkst? Dij van mie.\n",
      "Translation: mienent\n",
      "Translation: dienent\n",
      "Translation: hunnen\n",
      "Translation: dij van heur\n",
      "Translation: dij van heur\n",
      "Translation: joe\n",
      "Translation: van joe\n",
      "Translation: fijn kletswerk\n",
      "Language pair updated to: gos_Latn -> nld_Latn\n",
      "Translation: je kunt me echt niets vertellen mijn jongen, want ik ben een G\n",
      "Translation: beide afzonderlijke functie-definities zijn identiek in functionaliteit. De keuze om een komma op het laatste punt te plaatsen is vooral een stijldoekje\n",
      "Translation: wat voor een dinkje?\n",
      "Translation: wat\n",
      "Translation: bij zomerdag ga ik in de vijver zwemmen\n",
      "Translation: u bent een dikke kerel\n",
      "Translation: ja mijn jongen het is niet anders\n",
      "Translation: wakker niet\n",
      "Translation: goedenacht\n",
      "Translation: goedenacht\n",
      "Translation: goedemorgen hoe staat het er bij u in leven bij\n",
      "Translation: als u uw wonderbaarlijke boel beschrijft\n",
      "Translation: als u uw wonderbaarlijke boel beschrijft\n",
      "Translation: jullie twee zijn derbij\n",
      "Translation: de derby\n",
      "Language pair updated to: gos_Latn -> spa_Latn\n",
      "Translation: hola mi hijo\n",
      "Translation: ¿Alguna vez has visto que una máquina de traducción puede traducir una frase del gronés al español?\n",
      "Translation: ¡Quieren sí intentar escribir gronés, pero esas palabras son tan duras! Pero también si ya conoces los términos con el gronés, esto es un complemento. Haga uso de ese nuevo control de la ortografía para escribir gronés!\n",
      "Translation: Después de instalar la herramienta de lenguaje (en cualquier forma que sea) se agrega la lista de palabras. Controla de forma simultánea sus palabras holandesas y groenlandesas. Tiene los mejores resultados y funciona perfectamente en el procesador de texto especial que la herramienta de lenguaje trae consigo. Aquí pueden escribir y conservar sus textos groenlandeses. Pero también pueden pegarse para controlar los bloques de letre. En la lista de palabras existente pueden usted agregarse doscientas palabras, pero también descargar y conservar. No es mejor?\n",
      "Exiting translation tool.\n"
     ]
    }
   ],
   "source": [
    "MODEL_SAVE_PATH = \"models/facebook/nllb-200-distilled-1.3B-nld-gos-20250331-182640\" # config[\"MODEL_SAVE_PATH\"]\n",
    "\n",
    "inputs = [\n",
    "    \"ik ben benieuwd of dit werkt.\",\n",
    "    \"jij bent het zusje van mijn buurman!\",\n",
    "    \"onverwachts kwamen de ouders van Bert op bezoek.\",\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \"de straatkat is een kat die op straat leeft.\",\n",
    "    \"hebben jullie dat gezegd?\",\n",
    "    \"de molenaar ziet jullie.\",\n",
    "    \"ik weet niet wat je bedoelt...\",\n",
    "    \"wiens linkerarm is het sterkste? die van mij.\"\n",
    "]\n",
    "\n",
    "main_tryout(MODEL_SAVE_PATH, config[\"new_lang_nllb\"], inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eerste niveau in 'models' bevat:\n",
      "['nllb-200-distilled-1.3B-nld-gos-20250315-203450', 'nllb-200-distilled-1.3B-nld-gos-20250315-203832', 'nllb-200-distilled-1.3B-nld-gos-20250329-113115', 'nllb-200-distilled-1.3B-nld-gos-20250315-203303', 'nllb-200-distilled-1.3B-nld-gos-20250315-204002']\n",
      "\n",
      "Tweede niveau in 'nllb-200-distilled-1.3B-nld-gos-20250315-203450' bevat:\n",
      "['config.txt']\n",
      "\n",
      "Tweede niveau in 'nllb-200-distilled-1.3B-nld-gos-20250315-203832' bevat:\n",
      "['config.txt']\n",
      "\n",
      "Tweede niveau in 'nllb-200-distilled-1.3B-nld-gos-20250329-113115' bevat:\n",
      "['config.txt']\n",
      "\n",
      "Tweede niveau in 'nllb-200-distilled-1.3B-nld-gos-20250315-203303' bevat:\n",
      "['config.txt']\n",
      "\n",
      "Tweede niveau in 'nllb-200-distilled-1.3B-nld-gos-20250315-204002' bevat:\n",
      "['config.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def print_directory_structure(base_dir: str):\n",
    "    \"\"\"\n",
    "    Print de structuur van mappen binnen de basisdirectory, tot twee niveaus diep.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        first_level = os.listdir(base_dir)\n",
    "        print(f\"Eerste niveau in '{base_dir}' bevat:\")\n",
    "        print(first_level)\n",
    "\n",
    "        for first_level_dir in first_level:\n",
    "            first_level_path = os.path.join(base_dir, first_level_dir)\n",
    "            if os.path.isdir(first_level_path):\n",
    "                second_level = os.listdir(first_level_path)\n",
    "                print(f\"\\nTweede niveau in '{first_level_dir}' bevat:\")\n",
    "                print(second_level)\n",
    "    except Exception as e:\n",
    "        print(f'Er is een fout opgetreden: {e}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_directory = 'models'\n",
    "    print_directory_structure(base_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nllb-tat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
