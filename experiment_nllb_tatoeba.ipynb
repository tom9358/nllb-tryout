{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model save path: models/nllb-200-distilled-1.3B-nld-gos-20250329-171749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tom.brand/miniforge3/envs/nllbtatoebat/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading necessary Tatoeba files...\n",
      "Links CSV already exists. Skipping download and unpacking.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 15141.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tatoeba/nld_sentences.tsv already exists. Skipping download and unpacking.\n",
      "tatoeba/gos_sentences.tsv already exists. Skipping download and unpacking.\n",
      "Setting up parallel corpus for nld_Latn gos_Latn\n",
      "Downloading necessary Tatoeba files...\n",
      "Links CSV already exists. Skipping download and unpacking.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 17015.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tatoeba/nld_sentences.tsv already exists. Skipping download and unpacking.\n",
      "tatoeba/gos_sentences.tsv already exists. Skipping download and unpacking.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from config import source_langs_tatoeba, source_langs_nllb, MODEL_SAVE_PATH, new_lang_nllb\n",
    "from downloadtatoeba import main_download\n",
    "from corpus import main_corpus\n",
    "from train import main_train\n",
    "from evaluate import main_evaluate\n",
    "from tryout import main_tryout\n",
    "\n",
    "# Step 1: Download data\n",
    "main_download(source_langs_tatoeba)\n",
    "\n",
    "# Step 2: Load and create parallel corpus\n",
    "corpus_objects = main_corpus(source_langs_tatoeba, source_langs_nllb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.is_available(): True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tom.brand/miniforge3/envs/nllbtatoebat/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/tom.brand/miniforge3/envs/nllbtatoebat/lib/python3.11/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/tom.brand/miniforge3/envs/nllbtatoebat/lib/python3.11/site-packages/transformers/modeling_utils.py:488: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=map_location)\n",
      "/home/tom.brand/miniforge3/envs/nllbtatoebat/lib/python3.11/site-packages/transformers/modeling_utils.py:488: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=map_location)\n",
      "/home/tom.brand/miniforge3/envs/nllbtatoebat/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 256205. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized weights for gos_Latn equal to those of nld_Latn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Steps: 100%|██████████| 400/400 [04:55<00:00,  1.35it/s, loss=0.455]\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Train the model\n",
    "main_train(corpus_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from models/nllb-200-distilled-1.3B-nld-gos-20250329-160527/399...\n",
      "torch.cuda.is_available(): True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tom.brand/miniforge3/envs/nllbtatoebat/lib/python3.11/site-packages/transformers/modeling_utils.py:488: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=map_location)\n",
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 256205. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n",
      "Enter text to translate. Type 'END' to exit or use 'LANG src tgt' to change languages. Format e.g. nld_Latn gos_Latn\n",
      "Translate (nld_Latn -> gos_Latn): ik ben benieuwd of dit werkt.\n",
      "Translation: k Bin neudeg of dit waarkt.\n",
      "Translate (nld_Latn -> gos_Latn): jij bent het zusje van mijn buurman!\n",
      "Translation: bist mien noaber heur zuske!\n",
      "Translate (nld_Latn -> gos_Latn): onverwachts kwamen de ouders van Bert op bezoek.\n",
      "Translation: onwaarschoppelek kwammen ollu van Bert op bezeuk.\n",
      "Translate (nld_Latn -> gos_Latn): de straatkat is een kat die op straat leeft.\n",
      "Translation: stroatkat is n kadde dij op stroat leeft.\n",
      "Translate (nld_Latn -> gos_Latn): hebben jullie dat gezegd?\n",
      "Translation: hemmen joe dat zeden?\n",
      "Translate (nld_Latn -> gos_Latn): de molenaar ziet jullie.\n",
      "Translation: meulenoar zai joe.\n",
      "Translate (nld_Latn -> gos_Latn): ik weet niet wat je bedoelt...\n",
      "Translation: k Wait nait wat doe bedoulst...\n",
      "Translate (nld_Latn -> gos_Latn): wiens linkerarm is het sterkste? die van mij.\n",
      "Translation: wel zien linkerarm is t staarkst? mienent.\n",
      "Translation: mörgen komt der aine op bezeuk.\n",
      "Translation: k Lees kraande\n",
      "Translation: leesst kraande?\n",
      "Translation: hou loat begunt t?\n",
      "Translation: WAT IS DAT\n",
      "Translation: hai dreumt over gruinterij\n",
      "Translation: liest\n",
      "Translation: dikzak\n",
      "Translation: kloot\n",
      "Translation: kloot\n",
      "Translation: klots\n",
      "Translation: schavuit\n",
      "Translation: veurstelling\n",
      "Language pair updated to: gos_Latn -> nld_Latn\n",
      "Translation: moi jongen kun je mijn zin ook van het Gronings naar het Nederlands vertalen?\n",
      "Translation: Je kunt je niet voorstellen wat voor een mooie boel ik gemaakt heb\n",
      "Translation: hai het n dikke buik\n",
      "Exiting translation tool.\n"
     ]
    }
   ],
   "source": [
    "MODEL_SAVE_PATH = \"models/nllb-200-distilled-1.3B-nld-gos-20250329-160527\"\n",
    "\n",
    "inputs = [\n",
    "    \"ik ben benieuwd of dit werkt.\",\n",
    "    \"jij bent het zusje van mijn buurman!\",\n",
    "    \"onverwachts kwamen de ouders van Bert op bezoek.\",\n",
    "    \"de straatkat is een kat die op straat leeft.\",\n",
    "    \"hebben jullie dat gezegd?\",\n",
    "    \"de molenaar ziet jullie.\",\n",
    "    \"ik weet niet wat je bedoelt...\",\n",
    "    \"wiens linkerarm is het sterkste? die van mij.\"\n",
    "]\n",
    "\n",
    "main_tryout(MODEL_SAVE_PATH, new_lang_nllb, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eerste niveau in 'models' bevat:\n",
      "['nllb-200-distilled-1.3B-nld-gos-20250315-203450', 'nllb-200-distilled-1.3B-nld-gos-20250315-203832', 'nllb-200-distilled-1.3B-nld-gos-20250329-113115', 'nllb-200-distilled-1.3B-nld-gos-20250315-203303', 'nllb-200-distilled-1.3B-nld-gos-20250315-204002']\n",
      "\n",
      "Tweede niveau in 'nllb-200-distilled-1.3B-nld-gos-20250315-203450' bevat:\n",
      "['config.txt']\n",
      "\n",
      "Tweede niveau in 'nllb-200-distilled-1.3B-nld-gos-20250315-203832' bevat:\n",
      "['config.txt']\n",
      "\n",
      "Tweede niveau in 'nllb-200-distilled-1.3B-nld-gos-20250329-113115' bevat:\n",
      "['config.txt']\n",
      "\n",
      "Tweede niveau in 'nllb-200-distilled-1.3B-nld-gos-20250315-203303' bevat:\n",
      "['config.txt']\n",
      "\n",
      "Tweede niveau in 'nllb-200-distilled-1.3B-nld-gos-20250315-204002' bevat:\n",
      "['config.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def print_directory_structure(base_dir: str):\n",
    "    \"\"\"\n",
    "    Print de structuur van mappen binnen de basisdirectory, tot twee niveaus diep.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        first_level = os.listdir(base_dir)\n",
    "        print(f\"Eerste niveau in '{base_dir}' bevat:\")\n",
    "        print(first_level)\n",
    "\n",
    "        for first_level_dir in first_level:\n",
    "            first_level_path = os.path.join(base_dir, first_level_dir)\n",
    "            if os.path.isdir(first_level_path):\n",
    "                second_level = os.listdir(first_level_path)\n",
    "                print(f\"\\nTweede niveau in '{first_level_dir}' bevat:\")\n",
    "                print(second_level)\n",
    "    except Exception as e:\n",
    "        print(f'Er is een fout opgetreden: {e}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_directory = 'models'\n",
    "    print_directory_structure(base_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nllbtatoebat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
